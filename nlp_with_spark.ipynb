{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# my local spark install\n",
    "findspark.init('/Users/dreyco676/spark-1.6.0-bin-hadoop2.6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# create spark contexts\n",
    "sc = pyspark.SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "import preproc as pp\n",
    "# Register all the functions in Preproc with Spark Context\n",
    "check_lang_udf = udf(pp.check_lang, StringType())\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())\n",
    "check_blanks_udf = udf(pp.check_blanks, StringType())\n",
    "numeric_label_udf = udf(pp.numeric_label, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text file and convert each line to a Row.\n",
    "data_rdd = sc.textFile(\"data/toy_set.txt\")\n",
    "parts_rdd = data_rdd.map(lambda l: l.split(\"\\t\"))\n",
    "# Filter bad rows out\n",
    "garantee_col_rdd = parts_rdd.filter(lambda l: len(l) == 3)\n",
    "# Create DataFrame\n",
    "data_df = sqlContext.createDataFrame(garantee_col_rdd, [\"text\", \"id\", \"text_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------+\n|                text|                id|text_label|\n+--------------------+------------------+----------+\n|What's my best op...|514511437985611776|    python|\n|RT @AnthonyNystro...|492887601045467137|    python|\n|RT @raymondh: #py...|464730495213768704|    python|\n|Checked out https...|443215773168066560|    python|\n|#openscience and ...|443004371425849344|    python|\n+--------------------+------------------+----------+\nonly showing top 5 rows\n\n+--------------------+------------------+----------+----+\n|                text|                id|text_label|lang|\n+--------------------+------------------+----------+----+\n|What's my best op...|514511437985611776|    python|  en|\n|RT @AnthonyNystro...|492887601045467137|    python|  en|\n|RT @raymondh: #py...|464730495213768704|    python|  en|\n|Checked out https...|443215773168066560|    python|  en|\n|#openscience and ...|443004371425849344|    python|  en|\n+--------------------+------------------+----------+----+\nonly showing top 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict language and filter out those with less than 90% chance of being English\n",
    "lang_df = data_df.withColumn(\"lang\", check_lang_udf(data_df[\"text\"]))\n",
    "en_df = lang_df.filter(lang_df[\"lang\"] == \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------+\n|text                                                                                                                             |\n+---------------------------------------------------------------------------------------------------------------------------------+\n|What's my best option for doing a MANOVA in #python ? A brief google search leaves me thinking R is the way to go. #pydata #stats|\n+---------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 1 row\n\n+--------------------------------------------------------------------------------------------------+\n|stop_text                                                                                         |\n+--------------------------------------------------------------------------------------------------+\n|What's best option MANOVA #python ? A brief google search leaves thinking R way go. #pydata #stats|\n+--------------------------------------------------------------------------------------------------+\nonly showing top 1 row\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words to reduce dimensionality\n",
    "rm_stops_df = en_df.withColumn(\"stop_text\", remove_stops_udf(en_df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------+\n|stop_text                                                                                                                                 |\n+------------------------------------------------------------------------------------------------------------------------------------------+\n|What's best option MANOVA #python ? A brief google search leaves thinking R way go. #pydata #stats                                        |\n|RT @AnthonyNystrom: ML py -&gt; curated list awesome Machine Learning frameworks, libraries software -&gt; https://t.co/leY5PUi7Lh #python|\n|RT @raymondh: #python data analysis commandment: Thou shalt access thine fields indexing. Instead, use #pandas dataframes namâ€¦            |\n|Checked https://t.co/Zj7Wry6vKh text-to-speech #python worked like champion box!                                                          |\n|#openscience #python peeps: want service share research data; looking @figshare want built-in ipython notebook viewing. Ideas?            |\n+------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n+------------------------------------------------------------------------------------------------------------+\n|feat_text                                                                                                   |\n+------------------------------------------------------------------------------------------------------------+\n|what  best option manova python  brief google search leaves thinking  way  pydata stats                     |\n|     curated list awesome machine learning frameworks libraries software  python                            |\n|  python data analysis commandment thou shalt access thine fields indexing instead use pandas dataframes    |\n|checked text  speech python worked like champion box                                                        |\n|openscience python peeps want service share research data looking want built  ipython notebook viewing ideas|\n+------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove other non essential words, think of it as my personal stop word list\n",
    "rm_features_df = rm_stops_df.withColumn(\"feat_text\", remove_features_udf(rm_stops_df[\"stop_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------+\n|feat_text                                                                                                   |\n+------------------------------------------------------------------------------------------------------------+\n|what  best option manova python  brief google search leaves thinking  way  pydata stats                     |\n|     curated list awesome machine learning frameworks libraries software  python                            |\n|  python data analysis commandment thou shalt access thine fields indexing instead use pandas dataframes    |\n|checked text  speech python worked like champion box                                                        |\n|openscience python peeps want service share research data looking want built  ipython notebook viewing ideas|\n+------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n+-------------------------------------------------------------------------------------------------------------+\n|tagged_text                                                                                                  |\n+-------------------------------------------------------------------------------------------------------------+\n| best option manova python brief google search leaves thinking way pydata stats                              |\n| curated list awesome machine learning frameworks libraries software python                                  |\n| python data analysis commandment thou shalt access thine fields indexing use pandas dataframes              |\n| checked text speech python worked champion box                                                              |\n| openscience python peeps want service share research data looking want built ipython notebook viewing ideas |\n+-------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "tagged_df = rm_features_df.withColumn(\"tagged_text\", tag_and_remove_udf(rm_features_df[\"feat_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+\n|tagged_text                                                                                                  |\n+-------------------------------------------------------------------------------------------------------------+\n| best option manova python brief google search leaves thinking way pydata stats                              |\n| curated list awesome machine learning frameworks libraries software python                                  |\n| python data analysis commandment thou shalt access thine fields indexing use pandas dataframes              |\n| checked text speech python worked champion box                                                              |\n| openscience python peeps want service share research data looking want built ipython notebook viewing ideas |\n| thanks missed john hunter rip matplotlib wonderful important legacy positivepython                          |\n| hats team fantastic way using python great stewardship project positivepython                               |\n| thanks virtualenvwrapper couldn productive positivepython                                                   |\n| thanks others responsible pandas hard calculate much time library saved positivepython                      |\n| thanks everyone else makes happen positivepython                                                            |\n| grateful hard work gone scientific python stack imagine science positivepython                              |\n| example morfessor trained using word corpus english anti dis establish ment arian ism python nlp            |\n| questions python don tweet use comp lang python look local user                                             |\n| thwarted hotel wifi flakey comp fine doesn needed files mysterious python versioning issues                 |\n| created many notebooks last days remember did need check logs nerdproblems ipython                          |\n+-------------------------------------------------------------------------------------------------------------+\n\n+---------------------------------------------------------------------------------------------------------+\n|lemm_text                                                                                                |\n+---------------------------------------------------------------------------------------------------------+\n|best option manova python brief google search leaf thinking way pydata stats                             |\n|curated list awesome machine learning framework library software python                                  |\n|python data analysis commandment thou shalt access thine field indexing use panda dataframes             |\n|checked text speech python worked champion box                                                           |\n|openscience python peep want service share research data looking want built ipython notebook viewing idea|\n|thanks missed john hunter rip matplotlib wonderful important legacy positivepython                       |\n|hat team fantastic way using python great stewardship project positivepython                             |\n|thanks virtualenvwrapper couldn productive positivepython                                                |\n|thanks others responsible panda hard calculate much time library saved positivepython                    |\n|thanks everyone else make happen positivepython                                                          |\n|grateful hard work gone scientific python stack imagine science positivepython                           |\n|example morfessor trained using word corpus english anti dis establish ment arian ism python nlp         |\n|question python don tweet use comp lang python look local user                                           |\n|thwarted hotel wifi flakey comp fine doesn needed file mysterious python versioning issue                |\n|created many notebook last day remember did need check log nerdproblems ipython                          |\n+---------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "lemm_df = tagged_df.withColumn(\"lemm_text\", lemmatize_udf(tagged_df[\"tagged_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows containing only blank spaces\n",
    "check_blanks_df = lemm_df.withColumn(\"is_blank\", check_blanks_udf(lemm_df[\"lemm_text\"]))\n",
    "no_blanks_df = check_blanks_df.filter(check_blanks_df[\"is_blank\"] == \"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_label_df = no_blanks_df.withColumn(\"label\", numeric_label_udf(no_blanks_df['text_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "num_label_df.withColumnRenamed(num_label_df[\"lemm_text\"], \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedupe important since alot of the tweets only differed by url's and RT mentions\n",
    "dedup_df = num_label_df.dropDuplicates(['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the columns we care about\n",
    "data_set = dedup_df.select(num_label_df['id'], num_label_df['text'], num_label_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training & validation sets with 60% to training and use a seed value of 1987\n",
    "splits = data_set.randomSplit([0.6, 0.4])\n",
    "training_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#\n",
    "#   Spark ML Section\n",
    "#   \n",
    "#   Skip Preprocessing and use cleaned files by running next cell\n",
    "#\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already cleaned data\n",
    "def reload_checkpoint(data_rdd):\n",
    "    parts_rdd = data_rdd.map(lambda l: l.split(\"\\t\"))\n",
    "    # Filter bad rows out\n",
    "    garantee_col_rdd = parts_rdd.filter(lambda l: len(l) == 3)\n",
    "    typed_rdd = garantee_col_rdd.map(lambda p: (p[0], p[1], float(p[2])))\n",
    "    # Create DataFrame\n",
    "    df = sqlContext.createDataFrame(typed_rdd, [\"id\", \"text\", \"label\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load precleaned training set\n",
    "training_rdd = sc.textFile(\"data/clean_training.txt\")\n",
    "training_df = reload_checkpoint(training_rdd)\n",
    "# Load precleaned test set\n",
    "test_rdd = sc.textFile(\"data/clean_test.txt\")\n",
    "test_df = reload_checkpoint(test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------+-----+----------+\n|text                                                                                                            |label|prediction|\n+----------------------------------------------------------------------------------------------------------------+-----+----------+\n|acolyte warmachine protectorateofmenoth                                                                         |1.0  |1.0       |\n|alfred producthunt workflow product hunt workflow alfred python                                                 |1.0  |0.0       |\n|alternative thanksgiving option inclined try something different year                                           |1.0  |1.0       |\n|america greatest country world truth                                                                            |1.0  |1.0       |\n|animatic hell lot better storyboards were le guesswork better camera angle acting hope                          |1.0  |1.0       |\n|annual spring clean day tomorrow june see list disposal cost applicable                                         |1.0  |1.0       |\n|anyone think security issue week problem understand industry                                                    |1.0  |1.0       |\n|are looking someone speak klingon december trekholiday                                                          |1.0  |1.0       |\n|avoid fine penalty email archiving solution                                                                     |1.0  |1.0       |\n|bad news toe bring count level make maya worry cpu running memory smoothing worth                               |1.0  |1.0       |\n|barton armed school child prevent school shooting wing watch                                                    |1.0  |1.0       |\n|basic classification neural network support vector machine                                                      |1.0  |1.0       |\n|bedfordshire police chief constable criminal prosecution file warren hill newmarket suffolk duke sutherland case|1.0  |1.0       |\n|beginning week january city continue rotational boulevard tree pruning cycle detail                             |1.0  |1.0       |\n|being new company market realize lack visibility decided provide gift                                           |1.0  |1.0       |\n|best part econ paper say mean stats summary bullshit                                                            |1.0  |1.0       |\n|best photo human san francisco took many attempt get                                                            |1.0  |1.0       |\n|better bulldog butt wiggle brain tail love concept video world mapped emotion                                   |1.0  |1.0       |\n|better throw same result gopher                                                                                 |1.0  |1.0       |\n|big boy toy drone next big thing bigdata according story iot                                                    |0.0  |1.0       |\n+----------------------------------------------------------------------------------------------------------------+-----+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "prediction_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+-----+----------+\n|text                                                                            |label|prediction|\n+--------------------------------------------------------------------------------+-----+----------+\n|big boy toy drone next big thing bigdata according story iot                    |0.0  |1.0       |\n|big data result depend data look                                                |0.0  |1.0       |\n|big data service say hadoop service inaccurate company                          |0.0  |0.0       |\n|big data wild                                                                   |0.0  |0.0       |\n|bigdata algorithm dominate life don consider datascience                        |0.0  |0.0       |\n|bigdata analytics maturity continuum matrix http                                |0.0  |0.0       |\n|cognitive technology microservices top analytics trend list bigdata cognitiveera|0.0  |0.0       |\n|company fight recruit data scientist mine big data                              |0.0  |1.0       |\n|data asset inconvenience bigdata analytics datascience                          |0.0  |0.0       |\n|data lover kirk borne know data datascience data iot                            |0.0  |0.0       |\n|data science hunch happens figure contradict gut instinct datascience           |0.0  |0.0       |\n|datascientists need good data storyteller abdsc bigdata datascience             |0.0  |0.0       |\n|facebook data scientist track rainbow profile photo                             |0.0  |1.0       |\n|foodindustry plan better blue yonder saas bigdata                               |0.0  |1.0       |\n|future datascience datascientists bigdata analytics                             |0.0  |0.0       |\n|gonzalezcarmen theiot slide evolution big data smart data cloudianp thingsexpo  |0.0  |0.0       |\n|important editorial bigdata amp datascience asa president statisticans role     |0.0  |0.0       |\n|intel doubling commitment open hadoop                                           |0.0  |0.0       |\n|iot analytics edge computing smart object abdsc bigdata datascience             |0.0  |0.0       |\n|irish start ups mining data science opportunity                                 |0.0  |1.0       |\n+--------------------------------------------------------------------------------+-----+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "datasci_df = prediction_df.filter(prediction_df['label']==0.0)\n",
    "datasci_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------+-----+----------+\n|text                                                                                                            |label|prediction|\n+----------------------------------------------------------------------------------------------------------------+-----+----------+\n|acolyte warmachine protectorateofmenoth                                                                         |1.0  |1.0       |\n|alfred producthunt workflow product hunt workflow alfred python                                                 |1.0  |0.0       |\n|alternative thanksgiving option inclined try something different year                                           |1.0  |1.0       |\n|america greatest country world truth                                                                            |1.0  |1.0       |\n|animatic hell lot better storyboards were le guesswork better camera angle acting hope                          |1.0  |1.0       |\n|annual spring clean day tomorrow june see list disposal cost applicable                                         |1.0  |1.0       |\n|anyone think security issue week problem understand industry                                                    |1.0  |1.0       |\n|are looking someone speak klingon december trekholiday                                                          |1.0  |1.0       |\n|avoid fine penalty email archiving solution                                                                     |1.0  |1.0       |\n|bad news toe bring count level make maya worry cpu running memory smoothing worth                               |1.0  |1.0       |\n|barton armed school child prevent school shooting wing watch                                                    |1.0  |1.0       |\n|basic classification neural network support vector machine                                                      |1.0  |1.0       |\n|bedfordshire police chief constable criminal prosecution file warren hill newmarket suffolk duke sutherland case|1.0  |1.0       |\n|beginning week january city continue rotational boulevard tree pruning cycle detail                             |1.0  |1.0       |\n|being new company market realize lack visibility decided provide gift                                           |1.0  |1.0       |\n|best part econ paper say mean stats summary bullshit                                                            |1.0  |1.0       |\n|best photo human san francisco took many attempt get                                                            |1.0  |1.0       |\n|better bulldog butt wiggle brain tail love concept video world mapped emotion                                   |1.0  |1.0       |\n|better throw same result gopher                                                                                 |1.0  |1.0       |\n|big idea disrupt top mind share prediction official linkedin blog                                               |1.0  |1.0       |\n+----------------------------------------------------------------------------------------------------------------+-----+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "ao_df = prediction_df.filter(prediction_df['label']==1.0)\n",
    "ao_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add join back to original text\n",
    "# TODO fix raw_classification labels\n",
    "# TODO show accuracy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228856806385485"
      ]
     },
     "execution_count": 12,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"precision\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}